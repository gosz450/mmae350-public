\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage{hyperref}

\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}

\begin{document}

\begin{center}
{\Large \textbf{MMAE 350 Homework 2: Direct Solvers, LU, and Performance}}\\[4pt]
{\normalsize Matrix Algebra and Computational Cost}\\[4pt]
{\normalsize Due 1/27/2026}
\end{center}

\vspace{6pt}

\textbf{Learning objectives.}
By completing this assignment, you will:
\begin{itemize}[leftmargin=1.2em]
\item Implement Gaussian elimination and LU factorization for dense linear systems.
\item Compare accuracy and runtime against optimized library solvers.
\item Use \texttt{Numba} to accelerate loop-based numerical code.
\item Interpret algorithmic scaling and performance limitations.
\end{itemize}

\vspace{6pt}

\textbf{Problem statement.}
You will solve linear systems
\[
A \mathbf{x} = \mathbf{b}
\]
of increasing size using multiple approaches and measure their computational cost. All computations are performed in Python.

To avoid numerical issues related to pivoting, you will generate \emph{symmetric positive definite} matrices of the form
\[
\mathbf{A} = \mathbf{B}^T \mathbf{B} + \alpha \mathbf{I},
\]
with $\alpha>0$.

\vspace{6pt}

\textbf{Part A: Test system generation.}
For each system size
\[
n \in \{200,\;400,\;600,\;800\},
\]
generate a random matrix $\mathbf{B}$, construct $\mathbf{A} = \mathbf{B}^T \mathbf{B} + \alpha \mathbf{I}$ (use $\alpha=1$), and generate a random right-hand side $\mathbf{b}$. Use a fixed random seed for reproducibility.

\vspace{6pt}

\textbf{Part B: Solver implementation and accuracy.}
Implement the following methods:
\begin{enumerate}[leftmargin=1.2em]
\item Gaussian elimination with back substitution.
\item LU factorization followed by forward and back substitution.
\end{enumerate}

For each case, compute a reference solution using
\[
\mathbf{x}_{\text{ref}} = \texttt{numpy.linalg.solve}(A,\mathbf{b}),
\]
and report the relative error
\[
\frac{\|\mathbf{x}-\mathbf{x}_{\text{ref}}\|}{\|\mathbf{x}_{\text{ref}}\|}.
\]

\vspace{6pt}

\textbf{Part C: Timing (pure Python).}
Measure the CPU time required to solve the system using:
\begin{itemize}[leftmargin=1.2em]
\item your Gaussian elimination implementation,
\item your LU factorization and solve,
\item \texttt{numpy.linalg.solve}.
\end{itemize}

Repeat each timing three times and report the minimum time.

\vspace{6pt}

\textbf{Part D: Numba acceleration.}
Apply \texttt{@numba.njit} to \emph{your own} Gaussian elimination, LU factorization, and triangular solve routines.
\begin{itemize}[leftmargin=1.2em]
\item Do \emph{not} apply Numba to \texttt{numpy.linalg.solve}.
\item Perform one warm-up call before timing to exclude JIT compilation cost.
\end{itemize}

Compute and report the speedup
\[
\text{speedup} = \frac{t_{\text{Python}}}{t_{\text{Numba}}}.
\]

\vspace{6pt}

\textbf{Deliverables.}
Submit a PDF or notebook containing:
\begin{itemize}[leftmargin=1.2em]
\item A table of runtimes and relative errors for all methods.
\item A plot of CPU time versus system size $n$.
\item Short written responses (3--6 sentences each):
\begin{enumerate}[leftmargin=1.2em]
\item Why does Numba not speed up \texttt{numpy.linalg.solve}?
\item Why do loop-based solvers benefit from Numba?
\item Which method scales best in your results, and why?
\item What practical limitations appear as $n$ increases?
\end{enumerate}
\end{itemize}

\vspace{6pt}

\textbf{Important note.}
This assignment is designed to highlight that \emph{algorithm choice matters more than hardware}. Optimized library solvers rely on compiled linear algebra routines, while custom numerical methods require careful performance considerations to scale effectively.

\end{document}